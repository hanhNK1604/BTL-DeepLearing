{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4093964,"sourceType":"datasetVersion","datasetId":2421816}],"dockerImageVersionId":30214,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-19T05:02:27.990760Z","iopub.execute_input":"2024-06-19T05:02:27.991698Z","iopub.status.idle":"2024-06-19T05:02:27.999459Z","shell.execute_reply.started":"2024-06-19T05:02:27.991656Z","shell.execute_reply":"2024-06-19T05:02:27.998419Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"/kaggle/input/mt-en-vi/src-train.txt\n/kaggle/input/mt-en-vi/tgt-val.txt\n/kaggle/input/mt-en-vi/src-val.txt\n/kaggle/input/mt-en-vi/tgt-train.txt\n/kaggle/input/mt-en-vi/src-test.txt\n/kaggle/input/mt-en-vi/tgt-test.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Fine-tune mBART50 in translation English to Vietnamese task\n> this notebook use IWSLT2015 English-Vietnamese dataset","metadata":{}},{"cell_type":"code","source":"!pip install transformers\n!pip install datasets\n!pip install sacrebleu\n!pip insall accelerate","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:02:28.003416Z","iopub.execute_input":"2024-06-19T05:02:28.003706Z","iopub.status.idle":"2024-06-19T05:03:02.698062Z","shell.execute_reply.started":"2024-06-19T05:02:28.003679Z","shell.execute_reply":"2024-06-19T05:03:02.696844Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.5.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.8.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.12.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.9)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: sacrebleu in /opt/conda/lib/python3.7/site-packages (2.4.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (1.21.6)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2.5.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2021.11.10)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (4.9.1)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.4.5)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.8.10)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mERROR: unknown command \"insall\" - maybe you meant \"install\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import (\n    MBartForConditionalGeneration, MBartTokenizer, \n    Seq2SeqTrainingArguments, Seq2SeqTrainer\n  )\n\nimport torch\nfrom torch.utils.data import random_split\nimport datasets\nimport pandas as pd\nfrom transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nimport numpy as np\nfrom datasets import load_metric\nimport gc\nimport torch\nfrom transformers import AutoTokenizer\nimport datasets","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:03:02.700642Z","iopub.execute_input":"2024-06-19T05:03:02.701464Z","iopub.status.idle":"2024-06-19T05:03:02.708608Z","shell.execute_reply.started":"2024-06-19T05:03:02.701416Z","shell.execute_reply":"2024-06-19T05:03:02.707503Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# /kaggle/input/mt-en-vi/src-train.txt\n# /kaggle/input/mt-en-vi/tgt-val.txt\n# /kaggle/input/mt-en-vi/src-val.txt\n# /kaggle/input/mt-en-vi/tgt-train.txt\n# /kaggle/input/mt-en-vi/src-test.txt\n# /kaggle/input/mt-en-vi/tgt-test.txt\ndef load_test():\n  data = []\n  with open(\"/kaggle/input/mt-en-vi/src-test.txt\") as f1, open(\"/kaggle/input/mt-en-vi/tgt-test.txt\") as f2:\n      for src, tgt in zip(f1, f2):\n        data.append(\n            {\n                \"translation\": {\n                    \"en\": src.strip(),\n                    \"vi\": tgt.strip()\n                }\n            }\n        )\n  print(f'total size of data is {len(data)}')\n  tdata = pd.DataFrame(data)\n  tdata = tdata.reset_index()\n  tdata = tdata.rename(columns={'index': 'id'})\n  test = datasets.Dataset.from_pandas(tdata)\n  return test\n\ndef load_train():\n    data = []\n    with open(\"/kaggle/input/mt-en-vi/src-train.txt\") as f1, open(\"/kaggle/input/mt-en-vi/tgt-train.txt\") as f2:\n        for src, tgt in zip(f1, f2):\n          data.append(\n              {\n                  \"translation\": {\n                      \"en\": src.strip(),\n                      \"vi\": tgt.strip()\n                  }\n              }\n          )\n    print(f'total size of data is {len(data)}')\n    tdata = pd.DataFrame(data)\n    tdata = tdata.reset_index()\n    tdata = tdata.rename(columns={'index': 'id'})\n    dataset = datasets.Dataset.from_pandas(tdata)\n\n    # don't care about test_size. \n    downsampled_dataset = dataset.train_test_split(\n        train_size=9000, test_size=500, seed=69\n    )\n        \n    return downsampled_dataset\ntest_set = load_test()\ntrain_set = load_train()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:03:02.709833Z","iopub.execute_input":"2024-06-19T05:03:02.710162Z","iopub.status.idle":"2024-06-19T05:03:03.747577Z","shell.execute_reply.started":"2024-06-19T05:03:02.710108Z","shell.execute_reply":"2024-06-19T05:03:03.746681Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"total size of data is 1268\ntotal size of data is 133317\n","output_type":"stream"}]},{"cell_type":"code","source":"train_set","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:03:03.749703Z","iopub.execute_input":"2024-06-19T05:03:03.750010Z","iopub.status.idle":"2024-06-19T05:03:03.756190Z","shell.execute_reply.started":"2024-06-19T05:03:03.749981Z","shell.execute_reply":"2024-06-19T05:03:03.755311Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 500\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"checkpoint=\"facebook/mbart-large-50-many-to-many-mmt\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nprint(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:03:03.757376Z","iopub.execute_input":"2024-06-19T05:03:03.757724Z","iopub.status.idle":"2024-06-19T05:03:07.413750Z","shell.execute_reply.started":"2024-06-19T05:03:03.757689Z","shell.execute_reply":"2024-06-19T05:03:07.412551Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/529 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d844c97cdca44160a638c859bbdd8d33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58a7c7c442b84910838a55f5f8a9a76d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aff4f79eb3d84090a4b5e89c79003729"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cc8ea4f84514647968e30e90a9402c9"}},"metadata":{}},{"name":"stdout","text":"{'input_ids': [[250004, 35378, 4, 903, 1632, 149357, 38, 2], [250004, 3293, 83, 15700, 149357, 5, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n","output_type":"stream"}]},{"cell_type":"code","source":"model = MBartForConditionalGeneration.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:03:07.415057Z","iopub.execute_input":"2024-06-19T05:03:07.415385Z","iopub.status.idle":"2024-06-19T05:04:14.277922Z","shell.execute_reply.started":"2024-06-19T05:03:07.415356Z","shell.execute_reply":"2024-06-19T05:04:14.276849Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2ddfdcd325a424599c9f010eab58bf3"}},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 128\nmax_target_length = 128\nsource_lang = \"en\"\ntarget_lang = \"vi\"\n\ndef preprocess_function(examples):\n    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n    # Setup the tokenizer for targets\n    # no need this line \n    # with tokenizer.as_target_tokenizer():\n    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:04:14.279676Z","iopub.execute_input":"2024-06-19T05:04:14.279986Z","iopub.status.idle":"2024-06-19T05:04:14.287198Z","shell.execute_reply.started":"2024-06-19T05:04:14.279958Z","shell.execute_reply":"2024-06-19T05:04:14.286027Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = train_set.map(preprocess_function, batched=True)\ntokenized_test_set = test_set.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:04:14.288425Z","iopub.execute_input":"2024-06-19T05:04:14.288705Z","iopub.status.idle":"2024-06-19T05:04:15.963492Z","shell.execute_reply.started":"2024-06-19T05:04:14.288679Z","shell.execute_reply":"2024-06-19T05:04:15.962463Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db3e413da1334adfb5274d48f4cd1fca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d02f59b54993488f947d684e5e8a7c82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad1269888861464bb71b2b8cf1178369"}},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\nmetric = load_metric(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:04:15.964842Z","iopub.execute_input":"2024-06-19T05:04:15.965156Z","iopub.status.idle":"2024-06-19T05:04:16.492771Z","shell.execute_reply.started":"2024-06-19T05:04:15.965114Z","shell.execute_reply":"2024-06-19T05:04:16.491865Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66de8cc841e943e7b9929a0aa1b24607"}},"metadata":{}}]},{"cell_type":"code","source":"\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:04:16.496888Z","iopub.execute_input":"2024-06-19T05:04:16.497186Z","iopub.status.idle":"2024-06-19T05:04:16.507212Z","shell.execute_reply.started":"2024-06-19T05:04:16.497150Z","shell.execute_reply":"2024-06-19T05:04:16.506081Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from accelerate import Accelerator\naccelerator = Accelerator()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:04:16.508595Z","iopub.execute_input":"2024-06-19T05:04:16.508921Z","iopub.status.idle":"2024-06-19T05:04:16.568499Z","shell.execute_reply.started":"2024-06-19T05:04:16.508890Z","shell.execute_reply":"2024-06-19T05:04:16.567432Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# !wandb login --relogin","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:04:16.570060Z","iopub.execute_input":"2024-06-19T05:04:16.570923Z","iopub.status.idle":"2024-06-19T05:04:16.576294Z","shell.execute_reply.started":"2024-06-19T05:04:16.570889Z","shell.execute_reply":"2024-06-19T05:04:16.575353Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# release gpu ram\n# del trainer","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:06:37.560059Z","iopub.execute_input":"2024-06-19T05:06:37.560561Z","iopub.status.idle":"2024-06-19T05:06:37.565307Z","shell.execute_reply.started":"2024-06-19T05:06:37.560522Z","shell.execute_reply":"2024-06-19T05:06:37.564079Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# empty gpu ram\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:06:37.973853Z","iopub.execute_input":"2024-06-19T05:06:37.974260Z","iopub.status.idle":"2024-06-19T05:06:38.215852Z","shell.execute_reply.started":"2024-06-19T05:06:37.974223Z","shell.execute_reply":"2024-06-19T05:06:38.214817Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"5209"},"metadata":{}}]},{"cell_type":"code","source":"args = Seq2SeqTrainingArguments(output_dir=\"./mbart_EnglistToVietnamese/\",\n                        do_train=True,\n                        do_eval=True,\n                        evaluation_strategy=\"epoch\",\n                        per_device_train_batch_size=8,\n                        per_device_eval_batch_size=8,\n#                         gradient_accumulation_steps=4,\n                        learning_rate=5e-5,\n                        num_train_epochs=2,\n                        predict_with_generate=True,\n                        logging_dir=\"/logs\",\n                        logging_steps=10000,\n                        save_steps=10000,\n                        report_to=\"none\"\n                        )\n\n\ntrainer = Seq2SeqTrainer(model=model, \n                args=args,\n                data_collator=data_collator, \n                train_dataset=tokenized_datasets['train'],\n#                eval_dataset=tokenized_datasets['test'],\n                 eval_dataset=tokenized_test_set,\n                tokenizer=tokenizer,\n              compute_metrics=compute_metrics\n                )\n\ntokenized_datasets, tokenized_test_set, trainer = accelerator.prepare(\n     tokenized_datasets, tokenized_test_set, trainer\n      )\n\ntrainer.train()\n#trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:06:40.313031Z","iopub.execute_input":"2024-06-19T05:06:40.313815Z","iopub.status.idle":"2024-06-19T05:33:53.138540Z","shell.execute_reply.started":"2024-06-19T05:06:40.313778Z","shell.execute_reply":"2024-06-19T05:33:53.137565Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: id, translation. If id, translation are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 9000\n  Num Epochs = 2\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 2250\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2250/2250 27:06, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.377274</td>\n      <td>33.007900</td>\n      <td>33.500000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.442793</td>\n      <td>32.582000</td>\n      <td>33.666400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: id, translation. If id, translation are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 1268\n  Batch size = 8\nThe following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: id, translation. If id, translation are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 1268\n  Batch size = 8\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2250, training_loss=1.0253043619791666, metrics={'train_runtime': 1627.8042, 'train_samples_per_second': 11.058, 'train_steps_per_second': 1.382, 'total_flos': 2266580707442688.0, 'train_loss': 1.0253043619791666, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:33:53.140337Z","iopub.execute_input":"2024-06-19T05:33:53.140964Z","iopub.status.idle":"2024-06-19T05:33:54.145250Z","shell.execute_reply.started":"2024-06-19T05:33:53.140933Z","shell.execute_reply":"2024-06-19T05:33:54.144187Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nmbart_EnglistToVietnamese\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH = '/kaggle/working/mbartMT.pth'\ntorch.save(model.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:34:50.439052Z","iopub.execute_input":"2024-06-19T05:34:50.439998Z","iopub.status.idle":"2024-06-19T05:34:55.303568Z","shell.execute_reply.started":"2024-06-19T05:34:50.439960Z","shell.execute_reply":"2024-06-19T05:34:55.302666Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\nfrom IPython.display import FileLink\nFileLink('mbartMT.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-19T05:35:38.234453Z","iopub.execute_input":"2024-06-19T05:35:38.234837Z","iopub.status.idle":"2024-06-19T05:35:38.244460Z","shell.execute_reply.started":"2024-06-19T05:35:38.234805Z","shell.execute_reply":"2024-06-19T05:35:38.243446Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/mbartMT.pth","text/html":"<a href='mbartMT.pth' target='_blank'>mbartMT.pth</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}